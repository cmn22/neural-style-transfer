{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé® Neural Style Transfer - Interactive Demo\n",
    "\n",
    "This notebook demonstrates neural style transfer using a feedforward Transformer network.\n",
    "\n",
    "You can:\n",
    "- Upload your own content image, or choose one from examples.\n",
    "- Select a style from pretrained models (e.g., Starry Night, Mosaic).\n",
    "- Stylize the image and view the result interactively.\n",
    "- Compare before and after side by side.\n",
    "- Save the stylized image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "from utils.utils import prepare_img, post_process_image\n",
    "from utils.jupyter_parsing import parse_uploaded_file\n",
    "from models.definitions.transformer_net import TransformerNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üñºÔ∏è User Inputs: Select or Upload Content Image, and Choose Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "content_path = \"data/input\"\n",
    "output_path = \"data/output\"\n",
    "model_path = \"models/binaries\"\n",
    "\n",
    "# Available files\n",
    "available_images = sorted([f for f in os.listdir(content_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "available_styles = sorted([f for f in os.listdir(model_path) if f.endswith('.pth')])\n",
    "\n",
    "# Upload or choose image\n",
    "use_uploaded = widgets.Checkbox(value=False, description=\"Upload your own image\")\n",
    "uploader = widgets.FileUpload(accept=\".jpg,.png\", multiple=False)\n",
    "\n",
    "# Dropdowns\n",
    "image_dropdown = widgets.Dropdown(options=available_images, description=\"Choose Image:\")\n",
    "style_dropdown = widgets.Dropdown(options=available_styles, description=\"Choose Style:\")\n",
    "\n",
    "# Display widgets\n",
    "display(use_uploaded, uploader)\n",
    "display(image_dropdown, style_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üóÇÔ∏è Resolve Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_uploaded.value and uploader.value:\n",
    "    content_img_name = parse_uploaded_file(uploader, content_path)\n",
    "    print(f\"Uploaded image saved as: {content_img_name}\")\n",
    "else:\n",
    "    content_img_name = image_dropdown.value\n",
    "\n",
    "style_model_name = style_dropdown.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Stylization Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")    # for Apple Silicone\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")   # for Nvidia\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Load model\n",
    "model = TransformerNet().to(device)\n",
    "checkpoint = torch.load(os.path.join(model_path, style_model_name), map_location=device)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Prepare image\n",
    "img_path = os.path.join(content_path, content_img_name)\n",
    "input_tensor = prepare_img(img_path, target_shape=500, device=device)\n",
    "\n",
    "# Stylize\n",
    "with torch.no_grad():\n",
    "    output_tensor = model(input_tensor).cpu().numpy()[0]\n",
    "\n",
    "# Convert to displayable format\n",
    "stylized_img = post_process_image(output_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç View: Before vs After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "original_img = cv2.imread(img_path)[:, :, ::-1]  # BGR to RGB\n",
    "\n",
    "# Display side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axes[0].imshow(original_img)\n",
    "axes[0].set_title(\"Original Image\")\n",
    "axes[0].axis(\"off\")\n",
    "axes[1].imshow(stylized_img)\n",
    "axes[1].set_title(\"Stylized Image\")\n",
    "axes[1].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Save Stylized Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = f\"stylized_{Path(content_img_name).stem}_{Path(style_model_name).stem}.jpg\"\n",
    "save_path = os.path.join(output_path, save_name)\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "cv2.imwrite(save_path, cv2.cvtColor(stylized_img, cv2.COLOR_RGB2BGR))\n",
    "print(f\"Stylized image saved to: {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
